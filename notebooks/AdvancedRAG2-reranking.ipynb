{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aca1ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc30a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"REPLICATE_API_TOKEN\"]=\"r8_B4QZzdaf3iZheDalQ1PPMKhXxIOSf862e759H\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282820ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "api_key = \"7fc7d912-5d00-46ae-b73c-0eb78e3d128a\"\n",
    "pinecone.init(api_key=api_key, environment=\"gcp-starter\")\n",
    "\n",
    "pinecone_index = pinecone.Index(\"langchain-retrieval-agent\")\n",
    "\n",
    "from llama_index import VectorStoreIndex, ServiceContext\n",
    "from llama_index.vector_stores import PineconeVectorStore\n",
    "from data import *\n",
    "from llama_index.llms import Replicate\n",
    "vector_store = PineconeVectorStore(\n",
    "    pinecone_index=pinecone_index,\n",
    "    add_sparse_vector=True,\n",
    ")\n",
    "llm = Replicate(\n",
    "    model=\"mistralai/mistral-7b-instruct-v0.1:83b6a56e7c828e667f21fd596c338fd4f0039b46bcfa18d973e8e70e455fda70\"\n",
    ")\n",
    "embedding_model = get_embedding_model(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "service_context = ServiceContext.from_defaults(embed_model=embedding_model, llm=llm)\n",
    "index = VectorStoreIndex.from_vector_store(vector_store=vector_store, service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419e0657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9add98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.indices.postprocessor import SentenceTransformerRerank, LLMRerank\n",
    "\n",
    "st_reranker = SentenceTransformerRerank(\n",
    "    top_n=5, model=\"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
    ")\n",
    "\n",
    "llm_reranker = LLMRerank(\n",
    "    choice_batch_size=4, top_n=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003922ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "golden_dataset_path = Path(\"../datasets/eval_qs.json\")\n",
    "with open(golden_dataset_path, \"r\") as f:\n",
    "    golden_dataset = json.load(f)\n",
    "retrieval_queries = [item['question'] for item in golden_dataset]\n",
    "golden_sources = [item['source'] for item in golden_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a93ea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../datasets/golden-responses.json\", \"r\") as file:\n",
    "    golden_responses = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c084a5",
   "metadata": {},
   "source": [
    "#### Evaluate Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68789e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.indices.query.schema import QueryBundle\n",
    "\n",
    "class RetrieverWithRerank:\n",
    "    def __init__(self, retriever, reranker):\n",
    "        self.retriever = retriever\n",
    "        self.reranker = reranker\n",
    "\n",
    "    def retrieve(self, query):\n",
    "        nodes = self.retriever.retrieve(query) \n",
    "        nodes = self.reranker.postprocess_nodes(nodes, QueryBundle(query))\n",
    "        return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df669d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.evaluation import CorrectnessEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac0c115",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms import OpenAI\n",
    "from llama_index import VectorStoreIndex, ServiceContext\n",
    "eval_llm = PaLM(api_key=palm_api_key)\n",
    "service_context = ServiceContext.from_defaults(llm=eval_llm)\n",
    "evaluator = CorrectnessEvaluator(service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed13ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reranker experiment for retrieval:  SentenceTransformerRerank\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 2966/2966 [19:23<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval hit rate:  0.8202966958867162\n",
      "Running reranker experiment for retrieval:  LLMRerank\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/2966 [00:00<?, ?it/s]WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "  0%|                                                                                          | 0/2966 [01:12<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[93], line 8\u001b[0m\n",
      "\u001b[1;32m      5\u001b[0m retriever \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39mas_retriever(similarity_top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[1;32m      6\u001b[0m retriever \u001b[38;5;241m=\u001b[39m RetrieverWithRerank(retriever, reranker)\n",
      "\u001b[0;32m----> 8\u001b[0m retrieval_results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_retrieval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretriever\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretrieval_queries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgolden_sources\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m      9\u001b[0m hit_rate \u001b[38;5;241m=\u001b[39m get_hit_rate(retrieval_results)\n",
      "\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRetrieval hit rate: \u001b[39m\u001b[38;5;124m'\u001b[39m, hit_rate)\n",
      "\n",
      "File \u001b[0;32m/mnt/data1/aditi/ai-engineer-workshop/notebooks/eval.py:19\u001b[0m, in \u001b[0;36mevaluate_retrieval\u001b[0;34m(llama_index_retriever, queries, golden_sources)\u001b[0m\n",
      "\u001b[1;32m     16\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m query, expected_source \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(queries, golden_sources))):\n",
      "\u001b[0;32m---> 19\u001b[0m     retrieved_nodes \u001b[38;5;241m=\u001b[39m \u001b[43mllama_index_retriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     20\u001b[0m     retrieved_sources \u001b[38;5;241m=\u001b[39m [node\u001b[38;5;241m.\u001b[39mmetadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrug_link\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m retrieved_nodes]\n",
      "\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# If our label does not include a section, then any sections on the page should be considered a hit.\u001b[39;00m\n",
      "\n",
      "Cell \u001b[0;32mIn[89], line 10\u001b[0m, in \u001b[0;36mRetrieverWithRerank.retrieve\u001b[0;34m(self, query)\u001b[0m\n",
      "\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mretrieve\u001b[39m(\u001b[38;5;28mself\u001b[39m, query):\n",
      "\u001b[1;32m      9\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretriever\u001b[38;5;241m.\u001b[39mretrieve(query) \n",
      "\u001b[0;32m---> 10\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreranker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpostprocess_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQueryBundle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m nodes\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/llama_index/indices/postprocessor/llm_rerank.py:78\u001b[0m, in \u001b[0;36mLLMRerank.postprocess_nodes\u001b[0;34m(self, nodes, query_bundle)\u001b[0m\n",
      "\u001b[1;32m     76\u001b[0m fmt_batch_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_node_batch_fn(nodes_batch)\n",
      "\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# call each batch independently\u001b[39;00m\n",
      "\u001b[0;32m---> 78\u001b[0m raw_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mservice_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_predictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice_select_prompt\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfmt_batch_str\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     82\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     84\u001b[0m raw_choices, relevances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_choice_select_answer_fn(\n",
      "\u001b[1;32m     85\u001b[0m     raw_response, \u001b[38;5;28mlen\u001b[39m(nodes_batch)\n",
      "\u001b[1;32m     86\u001b[0m )\n",
      "\u001b[1;32m     87\u001b[0m choice_idxs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mint\u001b[39m(choice) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m choice \u001b[38;5;129;01min\u001b[39;00m raw_choices]\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/llama_index/llm_predictor/base.py:176\u001b[0m, in \u001b[0;36mLLMPredictor.predict\u001b[0;34m(self, prompt, output_cls, **prompt_args)\u001b[0m\n",
      "\u001b[1;32m    174\u001b[0m     messages \u001b[38;5;241m=\u001b[39m prompt\u001b[38;5;241m.\u001b[39mformat_messages(llm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprompt_args)\n",
      "\u001b[1;32m    175\u001b[0m     messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extend_messages(messages)\n",
      "\u001b[0;32m--> 176\u001b[0m     chat_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_llm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    177\u001b[0m     output \u001b[38;5;241m=\u001b[39m chat_response\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/llama_index/llms/base.py:151\u001b[0m, in \u001b[0;36mllm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat\u001b[0;34m(_self, messages, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m wrapper_logic(_self) \u001b[38;5;28;01mas\u001b[39;00m callback_manager:\n",
      "\u001b[1;32m    143\u001b[0m     event_id \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_event_start(\n",
      "\u001b[1;32m    144\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n",
      "\u001b[1;32m    145\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    149\u001b[0m         },\n",
      "\u001b[1;32m    150\u001b[0m     )\n",
      "\u001b[0;32m--> 151\u001b[0m     f_return_val \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f_return_val, Generator):\n",
      "\u001b[1;32m    154\u001b[0m         \u001b[38;5;66;03m# intercept the generator and add a callback to the end\u001b[39;00m\n",
      "\u001b[1;32m    155\u001b[0m         \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_gen\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResponseGen:\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/llama_index/llms/openai.py:124\u001b[0m, in \u001b[0;36mOpenAI.chat\u001b[0;34m(self, messages, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m    123\u001b[0m     chat_fn \u001b[38;5;241m=\u001b[39m completion_to_chat_decorator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_complete)\n",
      "\u001b[0;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mchat_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/llama_index/llms/openai.py:190\u001b[0m, in \u001b[0;36mOpenAI._chat\u001b[0;34m(self, messages, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_chat\u001b[39m(\u001b[38;5;28mself\u001b[39m, messages: Sequence[ChatMessage], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResponse:\n",
      "\u001b[1;32m    189\u001b[0m     message_dicts \u001b[38;5;241m=\u001b[39m to_openai_message_dicts(messages)\n",
      "\u001b[0;32m--> 190\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mcompletion_with_retry\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_chat_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_all_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    197\u001b[0m     message_dict \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;32m    198\u001b[0m     message \u001b[38;5;241m=\u001b[39m from_openai_message_dict(message_dict)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/llama_index/llms/openai_utils.py:139\u001b[0m, in \u001b[0;36mcompletion_with_retry\u001b[0;34m(is_chat_model, max_retries, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    136\u001b[0m     client \u001b[38;5;241m=\u001b[39m get_completion_endpoint(is_chat_model)\n",
      "\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m client\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_completion_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n",
      "\u001b[1;32m    287\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n",
      "\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n",
      "\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    377\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n",
      "\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[0;32m--> 379\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n",
      "\u001b[1;32m    381\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tenacity/__init__.py:325\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n",
      "\u001b[1;32m    323\u001b[0m     retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n",
      "\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n",
      "\u001b[0;32m--> 325\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
      "\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait:\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tenacity/__init__.py:158\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n",
      "\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n",
      "\u001b[0;32m--> 158\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n",
      "\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n",
      "\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n",
      "\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n",
      "\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n",
      "\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n",
      "\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 382\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n",
      "\u001b[1;32m    384\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/llama_index/llms/openai_utils.py:137\u001b[0m, in \u001b[0;36mcompletion_with_retry.<locals>._completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n",
      "\u001b[1;32m    134\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n",
      "\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n",
      "\u001b[1;32m    136\u001b[0m     client \u001b[38;5;241m=\u001b[39m get_completion_endpoint(is_chat_model)\n",
      "\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n",
      "\u001b[1;32m    129\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n",
      "\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n",
      "\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    138\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n",
      "\u001b[1;32m    139\u001b[0m ):\n",
      "\u001b[1;32m    140\u001b[0m     (\n",
      "\u001b[1;32m    141\u001b[0m         deployment_id,\n",
      "\u001b[1;32m    142\u001b[0m         engine,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n",
      "\u001b[1;32m    153\u001b[0m     )\n",
      "\u001b[0;32m--> 155\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n",
      "\u001b[1;32m    166\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n",
      "\u001b[1;32m    167\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py:299\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n",
      "\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n",
      "\u001b[1;32m    279\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n",
      "\u001b[1;32m    280\u001b[0m     method,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "\u001b[1;32m    288\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n",
      "\u001b[1;32m    289\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n",
      "\u001b[1;32m    290\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n",
      "\u001b[1;32m    291\u001b[0m         url,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    297\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n",
      "\u001b[1;32m    298\u001b[0m     )\n",
      "\u001b[0;32m--> 299\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py:710\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n",
      "\u001b[1;32m    702\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n",
      "\u001b[1;32m    703\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n",
      "\u001b[1;32m    704\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;32m    705\u001b[0m         )\n",
      "\u001b[1;32m    706\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n",
      "\u001b[1;32m    707\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n",
      "\u001b[0;32m--> 710\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    711\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    712\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    713\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    714\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    715\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n",
      "\u001b[1;32m    716\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "\u001b[1;32m    717\u001b[0m     )\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py:775\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n",
      "\u001b[1;32m    773\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n",
      "\u001b[1;32m    774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n",
      "\u001b[0;32m--> 775\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n",
      "\u001b[1;32m    776\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n",
      "\u001b[1;32m    777\u001b[0m     )\n",
      "\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\n",
      "\u001b[0;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details."
     ]
    }
   ],
   "source": [
    "from eval import *\n",
    "for reranker in [st_reranker]:\n",
    "    print('Running reranker experiment for retrieval: ', reranker.__class__.__name__)\n",
    "            \n",
    "    retriever = index.as_retriever(similarity_top_k=10)\n",
    "    retriever = RetrieverWithRerank(retriever, reranker)\n",
    "    \n",
    "    retrieval_results = evaluate_retrieval(retriever, retrieval_queries, golden_sources)\n",
    "    hit_rate = get_hit_rate(retrieval_results)\n",
    "    print('Retrieval hit rate: ', hit_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab82ca0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 12:14:10.563641: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-04 12:14:10.563737: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-04 12:14:10.565025: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-04 12:14:10.570525: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-04 12:14:11.329045: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reranker experiment for RAG:  SentenceTransformerRerank\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [01:02<00:00,  6.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Common side effects of doxycycline may include: nausea and vomiting; upset stomach; loss of appetite; mild diarrhea; skin rash or itching; darkened skin color; vaginal itching or discharge.\\n\\nHowever, it's important to note that more serious side effects can occur, such as severe stomach pain, diarrhea that is watery or bloody; throat irritation, trouble swallowing; chest pain, irregular heart rhythm, feeling short of breath; little or no urination; low white blood cell counts - fever, chills, swollen glands\", \"Spironolactone is a medication that can be used to treat a variety of conditions, including high blood pressure and fluid retention. Some common side effects of spironolactone include breast swelling or tenderness, dizziness, and leg cramps. However, more serious side effects can also occur, such as high potassium levels, low blood cell counts, and low sodium levels. It's important to speak with a healthcare provider if you experience any side effects while taking spironolactone.\", 'The side effects of minocycline may include increased tooth sensitivity, pain, headache, infection, or flu-like symptoms. More severe side effects can include fever, swollen glands, rash or itching, joint pain or swelling, muscle aches, general ill feeling, and severe skin reaction--fever, sore throat , swelling in your face or tongue, burning in your eyes, skin pain followed by a red or purple skin rash that spreads (especially in the face or upper body) and causes blistering and peeling. Common minocycline side effects may include numbness', 'The side effects of Accutane can include problems with your vision or hearing; muscle or joint pain, bone pain, back pain; increased thirst, increased urination; hallucinations, (seeing or hearing things that are not real); symptoms of depression - unusual mood changes, crying spells, feelings of low self-worth, loss of interest in things you once enjoyed, new sleep problems, thoughts about hurting yourself; signs of liver or pancreas problems - loss of appetite, upper stomach pain (that may spread to your back), nausea or vomiting, fast heart rate, dark urine,', 'Clindamycin topical may cause serious side effects, including severe redness, itching, or dryness of treated skin areas, severe stomach pain, diarrhea that is watery or bloody, and difficulty breathing or swelling of the face, lips, tongue, or throat. Common side effects may include burning, itching, dryness, peeling, or redness of treated skin, and oily skin. It is important to stop using clindamycin topical and call your doctor at once if you experience any of these side effects.', 'The common side effects of Aldactone may include breast swelling or tenderness.', 'The side effects of tretinoin may include: severe burning, stinging, or irritation of treated skin; severe skin dryness; or severe redness, swelling, blistering, peeling, or crusting. Your skin may be more sensitive to weather extremes such as cold and wind while using tretinoin. Common side effects may include: skin pain, redness, burning, itching, or irritation; sore throat ; mild warmth or stinging where the medicine was applied; or changes in color of treated skin.', 'The side effects of isotretinoin may include: dryness of your skin, lips, eyes, or nose (you may have nosebleeds); vision problems; headache, back pain, joint pain, muscle problems; skin reactions; or cold symptoms such as stuffy nose, sneezing, sore throat. Some serious side effects of isotretinoin may include: severe stomach problems such as severe stomach or chest pain, pain when swallowing, heartburn, diarrhea, rectal bleeding, bloody or tarry stools; or increased pressure inside the skull such as severe headaches, ringing', 'The side effects of Bactrim may include skin rash, fever, swollen glands, joint pain, muscle aches, severe weakness, pale skin, unusual bruising, or yellowing of your skin or eyes. Call your doctor at once if you have any of these symptoms. Common Bactrim side effects may include nausea, vomiting, loss of appetite; or skin rash.', 'The side effects of Retin-A may include mild warmth or stinging where the medicine is applied, changes in color of treated skin, severe burning, stinging, or irritation of treated skin, severe redness, swelling, blistering, peeling, or crusting, and difficulty breathing, swelling of the face, lips, tongue, or throat.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[12], line 21\u001b[0m\n",
      "\u001b[1;32m     18\u001b[0m     golden_answer \u001b[38;5;241m=\u001b[39m golden_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;32m     19\u001b[0m     generated_answer \u001b[38;5;241m=\u001b[39m rag_response\n",
      "\u001b[0;32m---> 21\u001b[0m     eval_result \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgolden_answer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerated_answer\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     22\u001b[0m     eval_results\u001b[38;5;241m.\u001b[39mappend(eval_result)\n",
      "\u001b[1;32m     24\u001b[0m scores \u001b[38;5;241m=\u001b[39m [\n",
      "\u001b[1;32m     25\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: golden_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n",
      "\u001b[1;32m     26\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgolden_response\u001b[39m\u001b[38;5;124m\"\u001b[39m: golden_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m eval_result, golden_response \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(eval_results, golden_responses)\n",
      "\u001b[1;32m     32\u001b[0m ]\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/llama_index/evaluation/base.py:44\u001b[0m, in \u001b[0;36mBaseEvaluator.evaluate\u001b[0;34m(self, query, response, contexts, **kwargs)\u001b[0m\n",
      "\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(\n",
      "\u001b[1;32m     32\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n",
      "\u001b[1;32m     33\u001b[0m     query: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m     36\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n",
      "\u001b[1;32m     37\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m EvaluationResult:\n",
      "\u001b[1;32m     38\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run evaluation with query string, retrieved contexts,\u001b[39;00m\n",
      "\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m    and generated response string.\u001b[39;00m\n",
      "\u001b[1;32m     40\u001b[0m \n",
      "\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m    Subclasses can override this method to provide custom evaluation logic and\u001b[39;00m\n",
      "\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03m    take in additional arguments.\u001b[39;00m\n",
      "\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maevaluate\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m     46\u001b[0m \u001b[43m            \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     47\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     48\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontexts\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     49\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/asyncio/runners.py:186\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n",
      "\u001b[1;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n",
      "\u001b[1;32m    162\u001b[0m \n",
      "\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n",
      "\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n",
      "\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n",
      "\u001b[1;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug\u001b[38;5;241m=\u001b[39mdebug) \u001b[38;5;28;01mas\u001b[39;00m runner:\n",
      "\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(main)\n",
      "\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "from eval import *\n",
    "for reranker in [st_reranker]:\n",
    "    print('Running reranker experiment for RAG: ', reranker.__class__.__name__)\n",
    "    query_engine = index.as_query_engine(similarity_top_k=10, node_postprocessors=[reranker])\n",
    "    \n",
    "    rag_responses = []\n",
    "    rag_response_str = []\n",
    "    for entry in tqdm(golden_responses):\n",
    "        query = entry[\"question\"]\n",
    "        response = query_engine.query(query)\n",
    "        rag_responses.append(response)\n",
    "        rag_response_str.append(response.response)\n",
    "    print(rag_response_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fefc048",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Using LlamaIndex Correctness Evaluator on Golden Responses Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b691f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reranker experiment for RAG:  SentenceTransformerRerank\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [02:27<00:00, 14.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End to end mean score:  3.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from eval import *\n",
    "for reranker in [st_reranker]:\n",
    "    print('Running reranker experiment for RAG: ', reranker.__class__.__name__)\n",
    "    eval_results = []\n",
    "    for rag_response, golden_response in tqdm(list(zip(rag_response_str, golden_responses))):\n",
    "        query = golden_response[\"question\"]\n",
    "        golden_answer = golden_response[\"response\"]\n",
    "        generated_answer = rag_response\n",
    "        \n",
    "        eval_result = evaluator.evaluate(query=query, reference=golden_answer, response=generated_answer)\n",
    "        eval_results.append(eval_result)\n",
    "\n",
    "    scores = [\n",
    "        {\"question\": golden_response[\"question\"],\n",
    "         \"golden_response\": golden_response[\"response\"],\n",
    "         \"generated_response\": eval_result.response,\n",
    "         \"score\": eval_result.score,\n",
    "         \"reasoning\": eval_result.feedback,\n",
    "        }\n",
    "        for eval_result, golden_response in zip(eval_results, golden_responses)\n",
    "    ]\n",
    "    file_name = f\"eval-scores-mistral-{str(reranker.__class__.__name__)}.json\"\n",
    "    with open(file_name, \"w\") as file:\n",
    "        json.dump(scores, file, indent=4)\n",
    "    average_scores = sum(score[\"score\"] for score in scores) / len(scores)\n",
    "    # mean_score = get_mean_score(e2e_results)\n",
    "    print('End to end mean score: ', average_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2666f1c6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Using LlamaIndex Correctness Evaluator on User Responses Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1521fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../datasets/eval-scores-mistral-SentenceTransformerRerank.json\", \"r\") as file:\n",
    "    pred_responses = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1805103f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [02:28<00:00, 14.86s/it]\n"
     ]
    }
   ],
   "source": [
    "eval_results = []\n",
    "from tqdm import tqdm\n",
    "for pred_response, golden_response in tqdm(list(zip(pred_responses, golden_responses))):\n",
    "    query = golden_response[\"question\"]\n",
    "    golden_answer = golden_response[\"response\"]\n",
    "    response = pred_response[\"generated_response\"]\n",
    "    \n",
    "    eval_result = evaluator.evaluate(query=query, reference=golden_answer, response=response)\n",
    "    eval_results.append(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edb767f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.5, 3.5, 3.5, 3.0, 4.5, 3.5, 4.5, 3.5, 3.5, 3.0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "[r.score for r in eval_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232c2765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = [\n",
    "    {\"question\": golden_response[\"question\"],\n",
    "     \"golden_response\": golden_response[\"response\"],\n",
    "     \"generated_response\": eval_result.response,\n",
    "     \"score\": eval_result.score,\n",
    "     \"reasoning\": eval_result.feedback,\n",
    "    }\n",
    "    for eval_result, golden_response in zip(eval_results, golden_responses)\n",
    "]\n",
    "with open(\"mistralrerankingvshuman.json\", \"w\") as file:\n",
    "    json.dump(scores, file, indent=4)\n",
    "average_scores = sum(score[\"score\"] for score in scores) / len(scores)\n",
    "average_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6f6ced",
   "metadata": {},
   "source": [
    "#### Evaluating Industry Metrics against Golden Responses Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0c748b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating ROUGE Score...\n",
      "Calculating BLEU Score...\n",
      "Calculating BERT Score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating METEOR Score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"../datasets/eval-scores-bare-mistral.json\", \"r\") as file:\n",
    "    bare_llm = json.load(file)\n",
    "with open(\"../datasets/eval-scores-rag-mistral.json\", \"r\") as file:\n",
    "    rag = json.load(file)\n",
    "with open(\"../datasets/eval-scores-mistral-SentenceTransformerRerank.json\", \"r\") as file:\n",
    "    rerank = json.load(file)\n",
    "with open(\"../datasets/golden-responses.json\", \"r\") as file:\n",
    "    golden = json.load(file)\n",
    "\n",
    "rag_responses = []\n",
    "rerank_responses = []\n",
    "bare_responses = []\n",
    "golden_responses = []\n",
    "for i in range(0, 10):\n",
    "    rag_responses.append(rag[i][\"generated_response\"])\n",
    "    bare_responses.append(bare_llm[i][\"generated_response\"])\n",
    "    rerank_responses.append(rerank[i][\"generated_response\"])\n",
    "    golden_responses.append(golden[i][\"response\"])\n",
    "    \n",
    "predictions_dict = {\n",
    "    \"Bare Mistral LLM\": bare_responses,\n",
    "    \"Mistral + RAG\": rag_responses,\n",
    "    \"Mistral + RAG + ST Reranking\": rerank_responses,\n",
    "}\n",
    "from eval import generate_metrics_summary\n",
    "result = generate_metrics_summary(golden_responses, predictions_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1dcdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"meteor\"].to_csv('r.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a7a67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         System    rouge1    rouge2    rougeL  rougeLsum\n",
      "0              Bare Mistral LLM  0.253411  0.070328  0.174729   0.195600\n",
      "1                 Mistral + RAG  0.622169  0.501659  0.479202   0.493566\n",
      "2  Mistral + RAG + ST Reranking  0.609687  0.485673  0.490000   0.511075\n"
     ]
    }
   ],
   "source": [
    "print(result[\"rouge\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b360db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         System      bleu\n",
      "0              Bare Mistral LLM  0.039006\n",
      "1                 Mistral + RAG  0.365213\n",
      "2  Mistral + RAG + ST Reranking  0.325257\n"
     ]
    }
   ],
   "source": [
    "print(result[\"bleu\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958cef2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         System    meteor\n",
      "0              Bare Mistral LLM  0.239231\n",
      "1                 Mistral + RAG  0.609384\n",
      "2  Mistral + RAG + ST Reranking  0.599952\n"
     ]
    }
   ],
   "source": [
    "print(result[\"meteor\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c600f77e-95fd-44b2-bcbb-8d7e861e0975",
   "metadata": {},
   "source": [
    "#### Industry Metrics on User Responses Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ea0fe2b-6072-4399-bc46-a7e28db267f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../datasets/human1_responses.json\", \"r\") as file:\n",
    "    human1 = json.load(file)\n",
    "with open(\"../datasets/human2_responses.json\", \"r\") as file:\n",
    "    human2 = json.load(file)\n",
    "with open(\"../datasets/human3_responses.json\", \"r\") as file:\n",
    "    human3 = json.load(file)\n",
    "with open(\"../datasets/eval-scores-mistral-SentenceTransformerRerank.json\", \"r\") as file:\n",
    "    eval = json.load(file)\n",
    "\n",
    "human1_responses = []\n",
    "human2_responses = []\n",
    "human3_responses = []\n",
    "eval_responses = []\n",
    "\n",
    "for i in range(0, 10):\n",
    "    human1_responses.append(human1[i][\"response\"])\n",
    "    human2_responses.append(human2[i][\"response\"])\n",
    "    human3_responses.append(human3[i][\"response\"])\n",
    "    eval_responses.append(eval[i][\"generated_response\"])\n",
    "    \n",
    "references_dict = {\n",
    "    \"human_1\": human1_responses,\n",
    "    \"human_2\": human2_responses,\n",
    "    \"human_3\": human3_responses,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e68fb18d-50d3-44ea-9b0f-38e531fc6b18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating ROUGE Score...\n",
      "Calculating BLEU Score...\n",
      "Calculating BERT Score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating METEOR Score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from eval import generate_human_eval_summary\n",
    "reranking_vs_humans_result = generate_human_eval_summary(references_dict, eval_responses, \"Mistral + RAG + ST Reranking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfba2f18-6b4a-41ac-9a9c-30a9858bed8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mistral + RAG + ST Reranking    rouge1    rouge2    rougeL  rougeLsum\n",
      "0                      human_1  0.558579  0.391588  0.417520   0.419571\n",
      "1                      human_2  0.542093  0.349670  0.394496   0.389678\n",
      "2                      human_3  0.528703  0.368262  0.400251   0.405855\n"
     ]
    }
   ],
   "source": [
    "print(reranking_vs_humans_result[\"rouge\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9d4cf96-d933-4de8-ae50-aa73cd6a261c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mistral + RAG + ST Reranking      bleu\n",
      "0                      human_1  0.378117\n",
      "1                      human_2  0.378117\n",
      "2                      human_3  0.378117\n"
     ]
    }
   ],
   "source": [
    "print(reranking_vs_humans_result[\"bleu\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5672fecb-a722-41c9-810a-fd7362128ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mistral + RAG + ST Reranking    meteor\n",
      "0                      human_1  0.456976\n",
      "1                      human_2  0.456976\n",
      "2                      human_3  0.456976\n"
     ]
    }
   ],
   "source": [
    "print(reranking_vs_humans_result[\"meteor\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
