{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "053e983f",
   "metadata": {},
   "source": [
    "Step 7: Use verified retrieved documents to Prompt LLM\n",
    "\n",
    "This is an advanced RAG Technique called Child-Parent RecursiveRetriever using Mistral LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbe92a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pinecone-client\n",
    "!pip install sentence-transformers\n",
    "!pip install llama-index --use-deprecated=legacy-resolver\n",
    "!pip install langchain\n",
    "!pip install replicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd4e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.response.notebook_utils import display_source_node\n",
    "from llama_index.retrievers import RecursiveRetriever\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "from llama_index import VectorStoreIndex, ServiceContext\n",
    "from llama_index.llms import OpenAI\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bebd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592f1a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pinecone\n",
    "api_key = \"3da0e6b6-40a1-4094-9ab1-ca22a2a98621\"\n",
    "pinecone.init(api_key=api_key, environment=\"gcp-starter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2037e98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.describe_index(\"langchain-rag\")\n",
    "pinecone_index = pinecone.Index(\"langchain-rag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af62b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, ServiceContext\n",
    "from llama_index.vector_stores import PineconeVectorStore\n",
    "\n",
    "vector_store = PineconeVectorStore(\n",
    "    pinecone_index=pinecone_index,\n",
    "    add_sparse_vector=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9896c2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"REPLICATE_API_TOKEN\"]=\"r8_B4QZzdaf3iZheDalQ1PPMKhXxIOSf862e759H\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e44954",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms import Replicate\n",
    "\n",
    "mistral = Replicate(\n",
    "    model=\"mistralai/mistral-7b-instruct-v0.1:83b6a56e7c828e667f21fd596c338fd4f0039b46bcfa18d973e8e70e455fda70\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e3839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our retriever.\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embed_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "service_context = ServiceContext.from_defaults(embed_model=embed_model, llm=mistral)\n",
    "index = VectorStoreIndex.from_vector_store(vector_store=vector_store, service_context=service_context)\n",
    "\n",
    "# Fetch the top 5 most relevant chunks.\n",
    "retriever = index.as_retriever(similarity_top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b28a994",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions =[\n",
    "    \"What are the side effects of doxycycline?\",\n",
    "    \"What are the side effects of spironolactone?\",\n",
    "    \"What are the side effects of minocycline?\",\n",
    "    \"What are the side effects of Accutane?\",\n",
    "    \"What are the side effects of clindamycin?\",\n",
    "    \"What are the side effects of Aldactone?\",\n",
    "    \"What are the side effects of tretinoin?\",\n",
    "    \"What are the side effects of isotretinoin?\",\n",
    "    \"What are the side effects of Bactrim ?\",\n",
    "    \"What are the side effects of Retin-A ?\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab88956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34mRetrieving with query id None: What are the side effects of doxycycline?\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: ceb9e608-bd70-441a-9d81-33d6c874640c\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id ceb9e608-bd70-441a-9d81-33d6c874640c: What are the side effects of doxycycline?\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What are the side effects of spironolactone?\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: d94975eb-c0a9-41fa-bb9f-2dd36abcdc96\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id d94975eb-c0a9-41fa-bb9f-2dd36abcdc96: What are the side effects of spironolactone?\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What are the side effects of minocycline?\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: d22268d4-1c7a-43ac-a5e5-6c57f5e1ecf2\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id d22268d4-1c7a-43ac-a5e5-6c57f5e1ecf2: What are the side effects of minocycline?\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What are the side effects of Accutane?\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: b77b120f-e126-4b0e-aeae-7eac312046a0\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id b77b120f-e126-4b0e-aeae-7eac312046a0: What are the side effects of Accutane?\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What are the side effects of clindamycin?\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: 06ef823f-5245-4f30-8100-4dd904c0c09e\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id 06ef823f-5245-4f30-8100-4dd904c0c09e: What are the side effects of clindamycin?\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What are the side effects of Aldactone?\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: c72e33f1-37d9-4b27-a22e-d1e1214ff0df\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id c72e33f1-37d9-4b27-a22e-d1e1214ff0df: What are the side effects of Aldactone?\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What are the side effects of tretinoin?\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: db0a5bbb-55d3-460e-9e0e-31dceeafd54e\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id db0a5bbb-55d3-460e-9e0e-31dceeafd54e: What are the side effects of tretinoin?\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What are the side effects of isotretinoin?\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: 92b1b25e-1ad6-4900-bac7-9b0daaef1e1b\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id 92b1b25e-1ad6-4900-bac7-9b0daaef1e1b: What are the side effects of isotretinoin?\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What are the side effects of Bactrim ?\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: abe2fb8e-e87b-4fac-a174-415242f0e076\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id abe2fb8e-e87b-4fac-a174-415242f0e076: What are the side effects of Bactrim ?\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id None: What are the side effects of Retin-A ?\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: bfa0f939-5dfc-4963-9d52-b4502bcd06cc\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id bfa0f939-5dfc-4963-9d52-b4502bcd06cc: What are the side effects of Retin-A ?\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "from llama_index import Document\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index.schema import IndexNode\n",
    "from llama_index.node_parser import SentenceSplitter\n",
    "\n",
    "responses = []\n",
    "for question in questions:\n",
    "  #query = \"What are the side effects of drugs?\"\n",
    "  nodes = retriever.retrieve(question)\n",
    "\n",
    "  doc_text = \"\\n\\n\".join([d.get_content() for d in nodes])\n",
    "\n",
    "  docs= [Document(text=doc_text)]\n",
    "\n",
    "  node_parser = SentenceSplitter(chunk_size=1024, chunk_overlap=20)\n",
    "\n",
    "  base_nodes = node_parser.get_nodes_from_documents(docs)\n",
    "\n",
    "  for idx, node in enumerate(base_nodes):\n",
    "    node.id_ = f\"node-{idx}\"\n",
    "\n",
    "  base_nodes = node_parser.get_nodes_from_documents(docs)\n",
    "\n",
    "  base_index = VectorStoreIndex(base_nodes, service_context=service_context)\n",
    "  base_retriever = base_index.as_retriever(similarity_top_k=2)\n",
    "\n",
    "  retrievals = base_retriever.retrieve(\n",
    "    question\n",
    "  )\n",
    "\n",
    "  query_engine_base = RetrieverQueryEngine.from_args(\n",
    "    base_retriever, service_context=service_context\n",
    "  )\n",
    "\n",
    "\n",
    "\n",
    "  #responses.append(str(response))\n",
    "  # print(str(response))\n",
    "  sub_chunk_sizes = [250, 256, 512]\n",
    "  sub_node_parsers = [\n",
    "    SimpleNodeParser.from_defaults(chunk_size=c) for c in sub_chunk_sizes\n",
    "  ]\n",
    "\n",
    "  all_nodes = []\n",
    "  for base_node in base_nodes:\n",
    "    for n in sub_node_parsers:\n",
    "        sub_nodes = n.get_nodes_from_documents([base_node])\n",
    "        sub_inodes = [\n",
    "            IndexNode.from_text_node(sn, base_node.node_id) for sn in sub_nodes\n",
    "        ]\n",
    "        all_nodes.extend(sub_inodes)\n",
    "\n",
    "    # also add original node to node\n",
    "    original_node = IndexNode.from_text_node(base_node, base_node.node_id)\n",
    "    all_nodes.append(original_node)\n",
    "\n",
    "  all_nodes_dict = {n.node_id: n for n in all_nodes}\n",
    "\n",
    "  vector_index_chunk = VectorStoreIndex(\n",
    "    all_nodes, service_context=service_context\n",
    "  )\n",
    "  vector_retriever_chunk = vector_index_chunk.as_retriever(similarity_top_k=2)\n",
    "\n",
    "  retriever_chunk = RecursiveRetriever(\n",
    "    \"vector\",\n",
    "    retriever_dict={\"vector\": vector_retriever_chunk},\n",
    "    node_dict=all_nodes_dict,\n",
    "    verbose=True,\n",
    "  )\n",
    "\n",
    "  query_engine = RetrieverQueryEngine.from_args(\n",
    "    retriever_chunk\n",
    "  )\n",
    "\n",
    "  response = query_engine.query(\n",
    "    question\n",
    "  )\n",
    "\n",
    "  responses.append(str(response))\n",
    "\n",
    "  # nodes = retriever_chunk.retrieve(\n",
    "  #   question\n",
    "\n",
    "  # )\n",
    "  # for node in nodes:\n",
    "  #   display_source_node(node, source_length=2000)\n",
    "\n",
    "  # response = query_engine_base.query(\n",
    "  #   question\n",
    "  # )\n",
    "\n",
    "\n",
    "\n",
    "# print(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bea9734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1: The side effects of doxycycline may include nausea and vomiting, upset stomach, loss of appetite, mild diarrhea, skin rash or itching, darkened skin color, vaginal itching or discharge. In rare cases, serious side effects may occur, such as severe stomach pain, diarrhea that is watery or bloody, throat irritation, trouble swallowing, chest pain, irregular heart rhythm, feeling short of breath, little or no urination, low white blood cell counts, severe headaches, ringing in the ears, dizziness, nausea, vision problems, pain behind the eyes, loss of appetite, upper stomach pain, tiredness, nausea or vomiting, fast heart rate, dark urine, jaundice.\n",
      "\n",
      "Response 2: The side effects of spironolactone may include breast swelling or tenderness, drowsiness, dizziness, lack of energy, leg cramps, weakness, feeling like you might pass out, severe pain in your upper stomach spreading to your back, nausea and vomiting, electrolyte imbalance, and high or low potassium levels.\n",
      "\n",
      "Response 3: The side effects of minocycline may include numbness, tingling, burning pain, hair loss, discoloration of the skin or nails, dizziness, spinning sensation, muscle or joint pain, nausea, diarrhea, loss of appetite, swollen tongue, cough, trouble swallowing, rash, itching, and headache. Serious side effects may include hives, itching, severe rash, swollen glands, unusual tiredness, fever, nausea, stomach pain, lower back pain, painful urination, blood or pus in the urine, chest pain, cough with mucus, difficult breathing, jaundice (yellowing of the skin or eyes), and swelling of the face, lips, tongue, or throat.\n",
      "\n",
      "Response 4: The side effects of Accutane may include problems with vision or hearing, muscle or joint pain, bone pain, back pain, increased thirst, increased urination, hallucinations, symptoms of depression, signs of liver or pancreas problems, severe stomach problems, increased pressure inside the skull, dryness of the skin, lips, eyes, or nose, vision problems, headache, skin reactions, and cold symptoms such as stuffy nose, sneezing, sore throat.\n",
      "\n",
      "Response 5: The side effects of clindamycin may include severe redness, itching, or dryness of treated skin areas, severe stomach pain, watery or bloody diarrhea, burning, itching, dryness, peeling or redness of treated skin, oily skin, nausea, vomiting, stomach pain, mild skin rash, vaginal itching or discharge, abdominal or stomach cramps, pain, and bloating, watery and severe diarrhea (which may also be bloody), fever, increased thirst, unusual tiredness or weakness, weight loss (unusual), skin rash, itching, redness, swelling, or other sign of irritation not present before use of the medicine, dryness, scaliness, or peeling of skin (for the topical solution), abdominal pain, mild diarrhea, headache, irritation or oiliness of skin, stinging or burning feeling of skin.\n",
      "\n",
      "Response 6: The side effects of Aldactone may include breast swelling or tenderness, drowsiness, dizziness, lack of energy, leg cramps, weakness, feeling like you might pass out, severe pain in your upper stomach spreading to your back, nausea and vomiting, electrolyte imbalance, and low blood cell counts.\n",
      "\n",
      "Response 7: The side effects of tretinoin may include severe burning, stinging, or irritation of treated skin, severe skin dryness, severe redness, swelling, blistering, peeling, or crusting of the skin, skin pain, redness, burning, itching, or irritation, sore throat, mild warmth or stinging where the medicine was applied, and changes in color of treated skin.\n",
      "\n",
      "Response 8: The side effects of isotretinoin may include problems with vision or hearing, muscle or joint pain, bone pain, back pain, increased thirst, increased urination, hallucinations, symptoms of depression, signs of liver or pancreas problems, severe stomach problems, increased pressure inside the skull, dryness of the skin, lips, eyes, or nose, vision problems, headache, skin reactions, and cold symptoms such as stuffy nose, sneezing, and sore throat.\n",
      "\n",
      "Response 9: The side effects of Bactrim may include nausea, vomiting, loss of appetite, and skin rash.\n",
      "\n",
      "Response 10: The side effects of Retin-A may include severe burning, stinging, or irritation of treated skin, severe redness, swelling, blistering, peeling, or crusting of the skin, mild warmth or stinging where the medicine was applied, and changes in color of treated skin.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for i in responses:\n",
    "#   print(i)\n",
    "#   print(len(i))\n",
    "for index, r in enumerate(responses):\n",
    "    print(f\"Response {index + 1}: {r}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc5f249",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99243a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "api_key = \"3da0e6b6-40a1-4094-9ab1-ca22a2a98621\"\n",
    "pinecone.init(api_key=api_key, environment=\"gcp-starter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5e3f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.describe_index(\"langchain-rag\")\n",
    "pinecone_index = pinecone.Index(\"langchain-rag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab4bbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, ServiceContext\n",
    "from llama_index.vector_stores import PineconeVectorStore\n",
    "\n",
    "vector_store = PineconeVectorStore(\n",
    "    pinecone_index=pinecone_index,\n",
    "    add_sparse_vector=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b5828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "with open(\"../datasets/child-recursive-responses.json\", 'r') as json_file:\n",
    "    rag_response_str = json.load(json_file)\n",
    "with open(\"../datasets/golden-responses.json\", 'r') as json_file:\n",
    "    golden_responses = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50d4561",
   "metadata": {},
   "source": [
    "#### Using LlamaIndex Correctness Evaluator on Golden Responses Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab61af14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.evaluation import CorrectnessEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd25e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms import OpenAI\n",
    "from llama_index import VectorStoreIndex, ServiceContext\n",
    "eval_llm = OpenAI(\"gpt-3.5-turbo\", temperature=0.0)\n",
    "service_context = ServiceContext.from_defaults(llm=eval_llm)\n",
    "evaluator = CorrectnessEvaluator(service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945118d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████████████████████████████████▌                                                                                                                          | 3/10 [00:11<00:25,  3.62s/it]WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-kdP6t2JxpPUqXQC2t4zLx3Mt on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-kdP6t2JxpPUqXQC2t4zLx3Mt on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      " 40%|██████████████████████████████████████████████████████████████████████                                                                                                         | 4/10 [00:23<00:40,  6.79s/it]WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-kdP6t2JxpPUqXQC2t4zLx3Mt on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-kdP6t2JxpPUqXQC2t4zLx3Mt on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-kdP6t2JxpPUqXQC2t4zLx3Mt on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-kdP6t2JxpPUqXQC2t4zLx3Mt on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      " 50%|███████████████████████████████████████████████████████████████████████████████████████▌                                                                                       | 5/10 [00:49<01:09, 13.97s/it]WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-kdP6t2JxpPUqXQC2t4zLx3Mt on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-kdP6t2JxpPUqXQC2t4zLx3Mt on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-kdP6t2JxpPUqXQC2t4zLx3Mt on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      " 60%|█████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                      | 6/10 [01:07<01:00, 15.15s/it]WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-kdP6t2JxpPUqXQC2t4zLx3Mt on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-kdP6t2JxpPUqXQC2t4zLx3Mt on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-kdP6t2JxpPUqXQC2t4zLx3Mt on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      " 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                    | 7/10 [01:22<00:45, 15.12s/it]WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-kdP6t2JxpPUqXQC2t4zLx3Mt on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-kdP6t2JxpPUqXQC2t4zLx3Mt on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-kdP6t2JxpPUqXQC2t4zLx3Mt on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-kdP6t2JxpPUqXQC2t4zLx3Mt on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised Timeout: Request timed out.\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [12:07<00:00, 72.76s/it]\n"
     ]
    }
   ],
   "source": [
    "eval_results = []\n",
    "from tqdm import tqdm\n",
    "for rag_response, golden_response in tqdm(list(zip(rag_response_str, golden_responses))):\n",
    "    query = golden_response[\"question\"]\n",
    "    golden_answer = golden_response[\"response\"]\n",
    "    generated_answer = rag_response[\"response\"]\n",
    "    \n",
    "    eval_result = evaluator.evaluate(query=query, reference=golden_answer, response=generated_answer)\n",
    "    eval_results.append(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bdd25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.5, 3.5, 4.5, 5.0, 3.0, 3.5, 5.0, 5.0, 5.0, 5.0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "[r.score for r in eval_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc84631",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [\n",
    "    {\"question\": golden_response[\"question\"],\n",
    "     \"golden_response\": golden_response[\"response\"],\n",
    "     \"generated_response\": eval_result.response,\n",
    "     \"score\": eval_result.score,\n",
    "     \"reasoning\": eval_result.feedback,\n",
    "    }\n",
    "    for eval_result, golden_response in zip(eval_results, golden_responses)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099f4a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"child-recursive-scores-mistral-goldeneval.json\", \"w\") as file:\n",
    "    json.dump(scores, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c030f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "average_scores = sum(score[\"score\"] for score in scores) / len(scores)\n",
    "average_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88044057",
   "metadata": {},
   "source": [
    "#### Using LlamaIndex Correctness Evaluator on User Responses Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cd0f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../datasets/child-recursive-scores-mistral-goldeneval.json\", \"r\") as file:\n",
    "    pred_responses = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe9f25b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [02:54<00:00, 17.46s/it]\n"
     ]
    }
   ],
   "source": [
    "eval_results = []\n",
    "from tqdm import tqdm\n",
    "for pred_response, golden_response in tqdm(list(zip(pred_responses, golden_responses))):\n",
    "    query = golden_response[\"question\"]\n",
    "    golden_answer = golden_response[\"response\"]\n",
    "    response = pred_response[\"generated_response\"]\n",
    "    \n",
    "    eval_result = evaluator.evaluate(query=query, reference=golden_answer, response=response)\n",
    "    eval_results.append(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d4b08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.0, 3.5, 3.5, 3.5, 3.0, 3.0, 4.5, 3.5, 4.5, 4.5]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "[r.score for r in eval_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa1e784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.75"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = [\n",
    "    {\"question\": golden_response[\"question\"],\n",
    "     \"golden_response\": golden_response[\"response\"],\n",
    "     \"generated_response\": eval_result.response,\n",
    "     \"score\": eval_result.score,\n",
    "     \"reasoning\": eval_result.feedback,\n",
    "    }\n",
    "    for eval_result, golden_response in zip(eval_results, golden_responses)\n",
    "]\n",
    "with open(\"mistralrecursivevshuman.json\", \"w\") as file:\n",
    "    json.dump(scores, file, indent=4)\n",
    "average_scores = sum(score[\"score\"] for score in scores) / len(scores)\n",
    "average_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97721f63",
   "metadata": {},
   "source": [
    "#### Industry Metrics on Golden Responses Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f96753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating ROUGE Score...\n",
      "Calculating BLEU Score...\n",
      "Calculating BERT Score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating METEOR Score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"../datasets/eval-scores-bare-mistral.json\", \"r\") as file:\n",
    "    bare_llm = json.load(file)\n",
    "with open(\"../datasets/eval-scores-rag-mistral.json\", \"r\") as file:\n",
    "    rag = json.load(file)\n",
    "with open(\"../datasets/child-recursive-scores-mistral-goldeneval.json\", \"r\") as file:\n",
    "    child = json.load(file) \n",
    "with open(\"../datasets/golden-responses.json\", \"r\") as file:\n",
    "    golden = json.load(file)\n",
    "\n",
    "rag_responses = []\n",
    "child_responses = []\n",
    "bare_responses = []\n",
    "golden_responses = []\n",
    "for i in range(0, 10):\n",
    "    rag_responses.append(rag[i][\"generated_response\"])\n",
    "    child_responses.append(child[i][\"generated_response\"])\n",
    "    bare_responses.append(bare_llm[i][\"generated_response\"])\n",
    "    golden_responses.append(golden[i][\"response\"])\n",
    "    \n",
    "predictions_dict = {\n",
    "    \"Bare Mistral LLM\": bare_responses,\n",
    "    \"Mistral + RAG\": rag_responses,\n",
    "    \"Mistral + RAG + Recursive-Retrieval \": child_responses,\n",
    "}\n",
    "from eval import generate_metrics_summary\n",
    "result = generate_metrics_summary(golden_responses, predictions_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5752e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"meteor\"].to_csv('r.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7fcb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 System    rouge1    rouge2    rougeL  \\\n",
      "0                      Bare Mistral LLM  0.252120  0.070203  0.175378   \n",
      "1                         Mistral + RAG  0.625968  0.502921  0.473645   \n",
      "2  Mistral + RAG + Recursive-Retrieval   0.774692  0.750064  0.743726   \n",
      "\n",
      "   rougeLsum  \n",
      "0   0.196235  \n",
      "1   0.490782  \n",
      "2   0.743960  \n"
     ]
    }
   ],
   "source": [
    "print(result['rouge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6755bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 System      bleu\n",
      "0                      Bare Mistral LLM  0.039006\n",
      "1                         Mistral + RAG  0.365213\n",
      "2  Mistral + RAG + Recursive-Retrieval   0.624797\n"
     ]
    }
   ],
   "source": [
    "print(result['bleu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f703329",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 System    meteor\n",
      "0                      Bare Mistral LLM  0.239231\n",
      "1                         Mistral + RAG  0.609384\n",
      "2  Mistral + RAG + Recursive-Retrieval   0.816886\n"
     ]
    }
   ],
   "source": [
    "print(result['meteor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5140767-c37e-457a-a5c0-5e5af99437cd",
   "metadata": {},
   "source": [
    "#### Industry Metrics on User Responses Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e4e5b04-a51b-480e-ad6b-5a4a6e787137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../datasets/human1_responses.json\", \"r\") as file:\n",
    "    human1 = json.load(file)\n",
    "with open(\"../datasets/human2_responses.json\", \"r\") as file:\n",
    "    human2 = json.load(file)\n",
    "with open(\"../datasets/human3_responses.json\", \"r\") as file:\n",
    "    human3 = json.load(file)\n",
    "with open(\"../datasets/child-recursive-scores-mistral.json\", \"r\") as file:\n",
    "    eval = json.load(file)\n",
    "\n",
    "human1_responses = []\n",
    "human2_responses = []\n",
    "human3_responses = []\n",
    "eval_responses = []\n",
    "\n",
    "for i in range(0, 10):\n",
    "    human1_responses.append(human1[i][\"response\"])\n",
    "    human2_responses.append(human2[i][\"response\"])\n",
    "    human3_responses.append(human3[i][\"response\"])\n",
    "    eval_responses.append(eval[i][\"generated_response\"])\n",
    "    \n",
    "references_dict = {\n",
    "    \"human_1\": human1_responses,\n",
    "    \"human_2\": human2_responses,\n",
    "    \"human_3\": human3_responses,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8861b625-70b7-4400-9182-bec1a0e88d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating ROUGE Score...\n",
      "Calculating BLEU Score...\n",
      "Calculating BERT Score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating METEOR Score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/aditi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from eval import generate_human_eval_summary\n",
    "recursive_vs_humans_result = generate_human_eval_summary(references_dict, eval_responses, \"Mistral + RAG + Recursive-Retrieval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "972a68e4-ef6e-4549-9b9b-a0c384d5260d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mistral + RAG + Recursive-Retrieval    rouge1    rouge2    rougeL  rougeLsum\n",
      "0                             human_1  0.584116  0.401521  0.404429   0.401688\n",
      "1                             human_2  0.570525  0.371188  0.382870   0.381524\n",
      "2                             human_3  0.530661  0.386513  0.442905   0.440329\n"
     ]
    }
   ],
   "source": [
    "print(recursive_vs_humans_result[\"rouge\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e4990d8-b116-4eeb-b2ac-65568f5a6895",
   "metadata": {},
   "outputs": [],
   "source": [
    "recursive_vs_humans_result[\"meteor\"].to_csv('r.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c97c3e0e-a50c-4a92-93a4-7109f4d8e9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mistral + RAG + Recursive-Retrieval      bleu\n",
      "0                             human_1  0.328418\n",
      "1                             human_2  0.328418\n",
      "2                             human_3  0.328418\n"
     ]
    }
   ],
   "source": [
    "print(recursive_vs_humans_result[\"bleu\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e6d4e90-e740-42fa-b211-c2db6afb6cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mistral + RAG + Recursive-Retrieval    meteor\n",
      "0                             human_1  0.400536\n",
      "1                             human_2  0.400536\n",
      "2                             human_3  0.400536\n"
     ]
    }
   ],
   "source": [
    "print(recursive_vs_humans_result[\"meteor\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
